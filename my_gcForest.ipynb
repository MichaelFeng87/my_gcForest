{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_predict as cvp\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MultiGrainedScaner():\n",
    "    def __init__(self, base_estimator, params_list, sliding_ratio = 0.25, k_fold = 3):\n",
    "        if k_fold > 1: #use cv\n",
    "            self.params_list = params_list\n",
    "        else:#use oob\n",
    "            self.params_list = [params.update({'oob_score':True}) or params for params in params_list]\n",
    "        self.sliding_ratio = sliding_ratio\n",
    "        self.k_fold = k_fold\n",
    "        self.base_estimator = base_estimator\n",
    "        klass = self.base_estimator.__class__\n",
    "        self.estimators = [klass(**params) for params in self.params_list]\n",
    "    \n",
    "    #generate scaned samples, X is not None, X[0] is no more than 3d\n",
    "    def _sample_slicer(self,X,y):\n",
    "        data_shape = X[0].shape\n",
    "        window_shape = [max(int(data_size * self.sliding_ratio),1) for data_size in data_shape]\n",
    "        scan_round_axis = [data_shape[i]-window_shape[i]+1 for i in range(len(data_shape))]\n",
    "        scan_round_total = reduce(lambda acc,x: acc*x,scan_round_axis)\n",
    "        if len(data_shape) == 1:\n",
    "            newX = np.array([x[beg:beg+window_shape[0]]\n",
    "                                for x in X\n",
    "                                    for beg in range(scan_round_axis[0])])\n",
    "        elif len(data_shape) == 2:\n",
    "            newX = np.array([x[beg0:beg0+window_shape[0],beg1:beg1+window_shape[1]].ravel()\n",
    "                                for x in X\n",
    "                                    for beg0 in range(scan_round_axis[0])\n",
    "                                        for beg1 in range(scan_round_axis[1])])\n",
    "        elif len(data_shape) == 3:\n",
    "            newX = np.array([x[beg0:beg0+window_shape[0],beg1:beg1+window_shape[1],beg2:beg2+window_shape[2]].ravel()\n",
    "                                for x in X\n",
    "                                    for beg0 in range(scan_round_axis[0])\n",
    "                                        for beg1 in range(scan_round_axis[1])\n",
    "                                            for beg2 in range(scan_round_axis[2])])\n",
    "        newy = y.repeat(scan_round_total)\n",
    "        return newX,newy,scan_round_total\n",
    "\n",
    "    #generate new sample vectors\n",
    "    def scan_fit(self,X,y):\n",
    "        self.n_classes = len(np.unique(y))\n",
    "        newX,newy,scan_round_total = self._sample_slicer(X,y)\n",
    "        sample_vector_list = []\n",
    "        for estimator in self.estimators:\n",
    "            estimator.fit(newX, newy)\n",
    "            if self.k_fold > 1:# use cv\n",
    "                predict_ = cvp(estimator, newX, newy, cv=self.k_fold, n_jobs = -1)\n",
    "            else:#use oob\n",
    "                predict_ = estimator.oob_decision_function_\n",
    "                #fill default value if meet nan\n",
    "                inds = np.where(np.isnan(predict_))\n",
    "                predict_[inds] = 1./self.n_classes\n",
    "            sample_vector = predict_.reshape((len(X),scan_round_total*self.n_classes))\n",
    "            sample_vector_list.append(sample_vector)\n",
    "        return np.hstack(sample_vector_list)\n",
    "\n",
    "    def scan_predict(self,X):\n",
    "        newX,newy,scan_round_total = self._sample_slicer(X,np.zeros(len(X)))\n",
    "        sample_vector_list = []\n",
    "        for estimator in self.estimators:\n",
    "            predict_ = estimator.predict(newX)\n",
    "            sample_vector = predict_.reshape((len(X),scan_round_total*self.n_classes))\n",
    "            sample_vector_list.append(sample_vector)\n",
    "        return np.hstack(sample_vector_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CascadeForest():\n",
    "    def __init__(self, base_estimator, params_list, k_fold = 3, evaluate = lambda pre,y: float(sum(pre==y))/len(y)):\n",
    "        if k_fold > 1: #use cv\n",
    "            self.params_list = params_list\n",
    "        else:#use oob\n",
    "            self.params_list = [params.update({'oob_score':True}) or params for params in params_list]\n",
    "        self.k_fold = k_fold\n",
    "        self.evaluate = evaluate\n",
    "        self.base_estimator = base_estimator\n",
    "#         base_class = base_estimator.__class__\n",
    "#         global prob_class\n",
    "#         class prob_class(base_class): #to use cross_val_predict, estimator's predict method should be predict_prob\n",
    "#             def predict(self, X):\n",
    "#                 return base_class.predict_proba(self, X)\n",
    "#         self.base_estimator = prob_class()\n",
    "    \n",
    "    def fit(self,X_train,y_train):\n",
    "        self.n_classes = len(np.unique(y_train))\n",
    "        self.estimators_levels = []\n",
    "        klass = self.base_estimator.__class__\n",
    "        predictions_levels = []\n",
    "        self.classes = np.unique(y_train)\n",
    "        \n",
    "        #first level\n",
    "        estimators = [klass(**params) for params in self.params_list]\n",
    "        self.estimators_levels.append(estimators)\n",
    "        predictions = []\n",
    "        for estimator in estimators:\n",
    "            estimator.fit(X_train, y_train)\n",
    "            if self.k_fold > 1:# use cv\n",
    "                predict_ = cvp(estimator, X_train, y_train, cv=self.k_fold, n_jobs = -1)\n",
    "            else:#use oob\n",
    "                predict_ = estimator.oob_decision_function_\n",
    "                #fill default value if meet nan\n",
    "                inds = np.where(np.isnan(predict_))\n",
    "                predict_[inds] = 1./self.n_classes\n",
    "            predictions.append(predict_)\n",
    "        attr_to_next_level = np.hstack(predictions)\n",
    "        y_pre = self.classes.take(np.argmax(np.array(predictions).mean(axis=0),axis=1),axis=0)\n",
    "        self.max_accuracy = self.evaluate(y_pre,y_train)\n",
    "        \n",
    "        #cascade step\n",
    "        while True:\n",
    "            print 'level {}, CV accuracy: {}'.format(len(self.estimators_levels),self.max_accuracy)\n",
    "            estimators = [klass(**params) for params in self.params_list]\n",
    "            self.estimators_levels.append(estimators)\n",
    "            predictions = []\n",
    "            X_train_step = np.hstack((attr_to_next_level,X_train))\n",
    "            for estimator in estimators:\n",
    "                estimator.fit(X_train_step, y_train)\n",
    "                if self.k_fold > 1:# use cv\n",
    "                    predict_ = cvp(estimator, X_train_step, y_train, cv=self.k_fold, n_jobs = -1)\n",
    "                else:#use oob\n",
    "                    predict_ = estimator.oob_decision_function_\n",
    "                    #fill default value if meet nan\n",
    "                    inds = np.where(np.isnan(predict_))\n",
    "                    predict_[inds] = 1./self.n_classes\n",
    "                predictions.append(predict_)\n",
    "            attr_to_next_level = np.hstack(predictions)\n",
    "            y_pre = self.classes.take(np.argmax(np.array(predictions).mean(axis=0),axis=1),axis=0)\n",
    "            accuracy = self.evaluate(y_pre,y_train)\n",
    "            if accuracy > self.max_accuracy:\n",
    "                self.max_accuracy = accuracy\n",
    "            else:\n",
    "                self.estimators_levels.pop()\n",
    "                break\n",
    "    \n",
    "    def predict_proba(self,X):\n",
    "        #first level\n",
    "        estimators = self.estimators_levels[0]\n",
    "        predictions = []\n",
    "        for estimator in estimators:\n",
    "            predict_ = estimator.predict(X)\n",
    "            predictions.append(predict_)\n",
    "        attr_to_next_level = np.hstack(predictions)\n",
    "        \n",
    "        #cascade step\n",
    "        for i in range(1,len(self.estimators_levels)):\n",
    "            estimators = self.estimators_levels[i]\n",
    "            predictions = []\n",
    "            X_step = np.hstack((attr_to_next_level,X))\n",
    "            for estimator in estimators:\n",
    "                predict_ = estimator.predict(X_step)\n",
    "                predictions.append(predict_)\n",
    "            attr_to_next_level = np.hstack(predictions)\n",
    "\n",
    "        #final step, calc prob\n",
    "        prediction_final = np.array(predictions).mean(axis=0) #不同estimator求平均\n",
    "        return prediction_final\n",
    "\n",
    "    def predict(self,X):\n",
    "        proba = self.predict_proba(X)\n",
    "        predictions = self.classes.take(np.argmax(proba,axis=1),axis=0) #平均值最大的index对应的class\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "\n",
    "# Trunk the data\n",
    "n_train = 60000\n",
    "n_test = 10000\n",
    "\n",
    "# Define training and testing sets\n",
    "train_idx = np.arange(n_train)\n",
    "test_idx = np.arange(n_test)+n_train\n",
    "random.shuffle(train_idx)\n",
    "\n",
    "X_train, y_train = mnist.data[train_idx], mnist.target[train_idx]\n",
    "X_test, y_test = mnist.data[test_idx], mnist.target[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scan_forest_params1 = RandomForestClassifier(n_estimators=30,min_samples_split=21,max_features=1,n_jobs=-1).get_params()\n",
    "scan_forest_params2 = RandomForestClassifier(n_estimators=30,min_samples_split=21,max_features='sqrt',n_jobs=-1).get_params()\n",
    "\n",
    "cascade_forest_params1 = RandomForestClassifier(n_estimators=1000,min_samples_split=11,max_features=1,n_jobs=-1).get_params()\n",
    "cascade_forest_params2 = RandomForestClassifier(n_estimators=1000,min_samples_split=11,max_features='sqrt',n_jobs=-1).get_params()\n",
    "\n",
    "scan_params_list = [scan_forest_params1,scan_forest_params2]\n",
    "cascade_params_list = [cascade_forest_params1,cascade_forest_params2]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_accuracy(pre,y):\n",
    "    return float(sum(pre==y))/len(y)\n",
    "class ProbRandomForestClassifier(RandomForestClassifier):\n",
    "    def predict(self, X):\n",
    "        return RandomForestClassifier.predict_proba(self, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# MultiGrainedScaner\n",
    "\n",
    "Scaner1 = MultiGrainedScaner(ProbRandomForestClassifier(), scan_params_list, sliding_ratio = 1./4)\n",
    "Scaner2 = MultiGrainedScaner(ProbRandomForestClassifier(), scan_params_list, sliding_ratio = 1./9)\n",
    "Scaner3 = MultiGrainedScaner(ProbRandomForestClassifier(), scan_params_list, sliding_ratio = 1./16)\n",
    "\n",
    "X_train_scan =np.hstack([scaner.scan_fit(X_train[:1000].reshape((1000,28,28)), y_train[:1000]) \n",
    "                             for scaner in [Scaner1]])#,Scaner2,Scaner3]])\n",
    "X_test_scan = np.hstack([scaner.scan_predict(X_test.reshape((10000,28,28)))\n",
    "                             for scaner in [Scaner1]])#,Scaner2,Scaner3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 1, CV accuracy: 0.94\n",
      "0.9607\n"
     ]
    }
   ],
   "source": [
    "# gcForest \n",
    "CascadeRF = CascadeForest(ProbRandomForestClassifier(),cascade_params_list)\n",
    "CascadeRF.fit(X_train_scan, y_train[:1000])\n",
    "y_pre = CascadeRF.predict(X_test_scan)\n",
    "print calc_accuracy(y_pre,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 1, CV accuracy: 0.857\n",
      "level 2, CV accuracy: 0.869\n",
      "level 3, CV accuracy: 0.872\n",
      "0.9139\n"
     ]
    }
   ],
   "source": [
    "#CascadeRF baseline\n",
    "CascadeRF = CascadeForest(ProbRandomForestClassifier(),cascade_params_list,k_fold=3)\n",
    "CascadeRF.fit(X_train[:1000], y_train[:1000])\n",
    "y_pre = CascadeRF.predict(X_test)\n",
    "print calc_accuracy(y_pre,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RF baseline\n",
    "RF = RandomForestClassifier(n_estimators=1000)\n",
    "RF.fit(X_train[:1000], y_train[:1000])\n",
    "y_pre = RF.predict(X_test)\n",
    "print calc_accuracy(y_pre,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
